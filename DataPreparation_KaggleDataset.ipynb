{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4081347e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Kaggle API if not already installed\n",
    "!pip install kaggle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce385bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload kaggle.json (API token)\n",
    "from google.colab import files\n",
    "files.upload()  # Upload kaggle.json here manually\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef30b555",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move kaggle.json to correct path\n",
    "!mkdir -p ~/.kaggle\n",
    "!cp kaggle.json ~/.kaggle/\n",
    "!chmod 600 ~/.kaggle/kaggle.json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8ff4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download Flowers Recognition Dataset from Kaggle\n",
    "!kaggle datasets download -d alxmamaev/flowers-recognition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12d1bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unzip dataset\n",
    "import zipfile\n",
    "with zipfile.ZipFile('flowers-recognition.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall('flowers_dataset')\n",
    "\n",
    "dataset_path = './flowers_dataset/flowers'\n",
    "print(\"Dataset extracted to:\", dataset_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97bb1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31997d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Augmentation and Preprocessing\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "# Training Data\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    dataset_path,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "# Validation Data\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "    dataset_path,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'\n",
    ")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
